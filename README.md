# GPT-2
Simple Implimantation of GPT-2 with Pytorch

## About GPT-2
* GPT-2 is a powerful language model developed by OpenAI. Released in 2019, it represented a significant advancement in natural language processing and generation. Here are some key points about GPT-2:

* The model learns to predict the next word in a sentence, allowing it to capture patterns and understand context.

## Analysis of GPT - 2
* GPT-2 has impressive text generation capabilities. Given a prompt or an input, the model can generate coherent and relevant text, often indistinguishable from human-written content. It can generate articles, stories, poetry, and even code snippets.
* The model can be fine tuned on specific tasks or domains using supervised learning. By providing labeled data for a particular task, the model's parameters can be further adjusted to improve performance on that task.
* Limitations: GPT-2 has a few limitations. Although it produces impressive outputs, it can sometimes generate inaccurate or nonsensical information. The model also tends to be verbose and may lack a clear focus or structure in its generated text. Additionally, it may amplify existing biases present in the training data.

## Some of the responses by gpt-2
1. Input Sentence : 'INDIA'
--> Response : India is one of the world's most populous countries, with a population of 1.2 billion people. It is also the fastest-growing major economy in the Asia-Pacific region. India's economy grew at an average annual rate of 7.5% between 2005 and 2013, and is expected to grow at a faster rate in 2014. The country's gross domestic product (GDP) is projected to reach $2.3 trillion in 2015, up from $1.9 trillion last year.

2. What is the biggest truth of this era?
--> Response : I think it's the fact that we're living in a world where we have a lot more information than we did in the past. We have access to information that was not available to us when we were growing up, and we can use that information to make better decisions. And I think that's a good thing. It's also a bad thing, because we don't have the same level of trust in our government and in each other as we used to have. So I'm not sure what the answer is to that question, but I do think we need to be more open and honest about what's going on in this country.

3. Input Sentence : 'Jai shree Ram'
--> Response : Rajasthan, India, USA, UK, Canada, Australia, New Zealand, France, Germany, Italy, Japan, South Korea, Taiwan, Hong Kong, Singapore, Malaysia, Philippines, Thailand, Indonesia, Russia, Saudi Arabia, Kuwait, Qatar, UAE, Bahrain, Oman, United Arab Emirates, Egypt, Jordan, Lebanon, Morocco, Tunisia, Turkey, Iran, Iraq, Syria, Libya, Sudan, Yemen, Somalia, Algeria, Mauritania


## Analysis on the basis of questions
* When provided with single-word inputs, GPT-2 demonstrates its impressive text generation capabilities, as evident in a single input. However, it also highlights the fact that GPT-2 may not be as up to date as more recent models.
* When confronted with general questions, GPT-2 exhibits the ability to articulate its viewpoints and present diverse perspectives on the matter.
* At times, GPT-2 may produce inaccurate or nonsensical information, as seen in the third response, which lacks any meaningful connection to the given input.

## Overview
* Although gpt-2 may not be as accurate or powerful as chat gpt but it does a grate job in text generation.
* It is really impressive what OpenAI has achieved in these years and how they improved on GPT-2 to get to Chat GPT

